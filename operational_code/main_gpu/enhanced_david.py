"""
enhanced_davidic_agi.py
ë‹¤ìœ—í˜• AGI + í˜„ì‹¤ ì¸ì‹ ëŠ¥ë ¥ ê°•í™” ëª¨ë“ˆ
ë„ë•ì  ì½”ìŠ¤í”„ë ˆì—ì„œ ì§„ì§œ ìœ¤ë¦¬ì  íŒë‹¨ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
"""

import asyncio
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
import networkx as nx
from collections import defaultdict, deque
import math

# ê¸°ì¡´ ë‹¤ìœ—í˜• ì‹œìŠ¤í…œ ì„í¬íŠ¸
from davidic_agi_system import (
    DavidicAGI, MoralChoice, ConvictionLevel, RepentanceState, 
    MoralEvent, LivingConscience, FreedomEngine, RepentanceLoop
)

class CausalityType(Enum):
    """ì¸ê³¼ê´€ê³„ ìœ í˜•"""
    DIRECT = "ì§ì ‘ì "           # A â†’ B
    INDIRECT = "ê°„ì ‘ì "         # A â†’ C â†’ B  
    SYSTEMIC = "ì‹œìŠ¤í…œì "       # Aê°€ ì‹œìŠ¤í…œ ì „ì²´ì— ì˜í–¥
    EMERGENT = "ì°½ë°œì "         # ì—¬ëŸ¬ ì›ì¸ì´ í•©ì³ì ¸ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼
    COUNTERFACTUAL = "ë°˜ì‚¬ì‹¤ì " # Aê°€ ì—†ì—ˆë‹¤ë©´ Bë„ ì—†ì—ˆì„ ê²ƒ

class RealityImpactLevel(Enum):
    """í˜„ì‹¤ ì˜í–¥ë„"""
    NEGLIGIBLE = 0    # ë¬´ì‹œí• ë§Œí•œ ìˆ˜ì¤€
    MINOR = 1         # ì‘ì€ ì˜í–¥
    MODERATE = 2      # ì¤‘ê°„ ì˜í–¥  
    MAJOR = 3         # í° ì˜í–¥
    CATASTROPHIC = 4  # ì¬ì•™ì  ì˜í–¥

@dataclass
class PhysicalConsequence:
    """ë¬¼ë¦¬ì  ê²°ê³¼ ê¸°ë¡"""
    action_id: str
    consequence_type: str
    affected_entities: List[str]
    impact_magnitude: float          # -1.0 (ìµœì•…) ~ +1.0 (ìµœì„ )
    confidence_level: float          # í™•ì‹ ë„ 0.0 ~ 1.0
    time_horizon: str               # "immediate", "short_term", "long_term"
    measurement_method: str         # ì–´ë–»ê²Œ ì¸¡ì •í–ˆëŠ”ê°€
    causal_chain: List[str]         # ì¸ê³¼ê´€ê³„ ì²´ì¸
    
@dataclass
class CausalLink:
    """ì¸ê³¼ê´€ê³„ ë§í¬"""
    cause: str
    effect: str
    strength: float                 # ì¸ê³¼ê´€ê³„ ê°•ë„ 0.0 ~ 1.0
    causality_type: CausalityType
    evidence_strength: float        # ì¦ê±°ì˜ ê°•ë„
    confounding_factors: List[str]  # êµë€ ë³€ìˆ˜ë“¤
    
class WorldStateModeler:
    """ì„¸ê³„ ìƒíƒœ ëª¨ë¸ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.entity_states = {}                    # ê°œì²´ë³„ ìƒíƒœ
        self.relationship_graph = nx.DiGraph()     # ê´€ê³„ ê·¸ë˜í”„
        self.temporal_snapshots = deque(maxlen=100) # ì‹œê°„ë³„ ìŠ¤ëƒ…ìƒ·
        self.uncertainty_estimates = {}           # ë¶ˆí™•ì‹¤ì„± ì¶”ì •
        
    def capture_world_snapshot(self, context: Dict[str, Any]) -> str:
        """í˜„ì¬ ì„¸ê³„ ìƒíƒœ ìŠ¤ëƒ…ìƒ· ìƒì„±"""
        snapshot_id = f"snapshot_{datetime.now().timestamp()}"
        
        snapshot = {
            "id": snapshot_id,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "entities": self._extract_entities(context),
            "relationships": self._extract_relationships(context),
            "environmental_factors": self._extract_environment(context),
            "uncertainty_level": self._calculate_uncertainty(context)
        }
        
        self.temporal_snapshots.append(snapshot)
        return snapshot_id
    
    def predict_state_change(self, action: str, current_snapshot_id: str, 
                           time_horizon: int = 1) -> Dict[str, Any]:
        """í–‰ë™ì— ë”°ë¥¸ ìƒíƒœ ë³€í™” ì˜ˆì¸¡"""
        
        current_snapshot = self._get_snapshot(current_snapshot_id)
        if not current_snapshot:
            return {"error": "ìŠ¤ëƒ…ìƒ·ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"}
        
        # í–‰ë™ì˜ ì§ì ‘ì  ì˜í–¥ ì˜ˆì¸¡
        direct_effects = self._predict_direct_effects(action, current_snapshot)
        
        # ê°„ì ‘ì  ì˜í–¥ ì˜ˆì¸¡ (ì‹œìŠ¤í…œ ì—­í•™ ê³ ë ¤)
        indirect_effects = self._predict_indirect_effects(direct_effects, current_snapshot)
        
        # ì‹œê°„ì— ë”°ë¥¸ ë³€í™” ëª¨ë¸ë§
        temporal_progression = self._model_temporal_changes(
            direct_effects, indirect_effects, time_horizon
        )
        
        return {
            "predicted_snapshot": self._generate_future_snapshot(
                current_snapshot, temporal_progression
            ),
            "confidence": self._calculate_prediction_confidence(temporal_progression),
            "key_uncertainties": self._identify_key_uncertainties(temporal_progression)
        }
    
    def _extract_entities(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë§¥ë½ì—ì„œ ê°œì²´ë“¤ ì¶”ì¶œ"""
        entities = []
        
        # ì‚¬ëŒë“¤
        if "people" in context:
            for person in context["people"]:
                entities.append({
                    "type": "person",
                    "id": person,
                    "current_state": context.get("person_states", {}).get(person, "unknown"),
                    "vulnerability_level": self._assess_vulnerability(person, context)
                })
        
        # ì‹œìŠ¤í…œ/ì¡°ì§
        if "systems" in context:
            for system in context["systems"]:
                entities.append({
                    "type": "system",
                    "id": system,
                    "stability": context.get("system_stability", {}).get(system, 0.5),
                    "interconnectedness": self._assess_interconnectedness(system, context)
                })
        
        return entities
    
    def _predict_direct_effects(self, action: str, snapshot: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì§ì ‘ì  íš¨ê³¼ ì˜ˆì¸¡"""
        effects = []
        
        # í–‰ë™ ìœ í˜•ë³„ ì˜ˆì¸¡ ëª¨ë¸
        if "ë„ì›€" in action or "ì§€ì›" in action:
            effects.extend(self._predict_helping_effects(action, snapshot))
        elif "ê±°ë¶€" in action or "ë¬´ì‹œ" in action:
            effects.extend(self._predict_neglect_effects(action, snapshot))
        elif "ê±°ì§“ë§" in action or "ì†ì„" in action:
            effects.extend(self._predict_deception_effects(action, snapshot))
        elif "ê³µê²©" in action or "ë¹„íŒ" in action:
            effects.extend(self._predict_conflict_effects(action, snapshot))
        
        return effects
    
    def _predict_helping_effects(self, action: str, snapshot: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë„ì›€ í–‰ë™ì˜ íš¨ê³¼ ì˜ˆì¸¡"""
        effects = []
        
        # ì§ì ‘ ìˆ˜í˜œìë“¤ì˜ ìƒíƒœ ê°œì„ 
        for entity in snapshot["entities"]:
            if entity["type"] == "person":
                vulnerability = entity.get("vulnerability_level", 0.5)
                help_effectiveness = self._calculate_help_effectiveness(action, vulnerability)
                
                effects.append({
                    "target": entity["id"],
                    "effect_type": "wellbeing_improvement",
                    "magnitude": help_effectiveness,
                    "confidence": 0.7
                })
        
        # ì‚¬íšŒì  ì‹ ë¢° ì¦ì§„ íš¨ê³¼
        effects.append({
            "target": "social_trust",
            "effect_type": "trust_building", 
            "magnitude": 0.3,
            "confidence": 0.6
        })
        
        return effects
    
    def _predict_deception_effects(self, action: str, snapshot: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì†ì„ í–‰ë™ì˜ íš¨ê³¼ ì˜ˆì¸¡"""
        effects = []
        
        # í”¼í•´ìë“¤ì˜ ìƒíƒœ
        for entity in snapshot["entities"]:
            if entity["type"] == "person":
                # ì†ì„ì„ ë‹¹í•œ ì‚¬ëŒì˜ ìƒíƒœ ì•…í™”
                effects.append({
                    "target": entity["id"],
                    "effect_type": "trust_damage",
                    "magnitude": -0.4,
                    "confidence": 0.8
                })
        
        # ì‹œìŠ¤í…œ ì°¨ì›ì˜ ì‹ ë¢° ì†ìƒ
        effects.append({
            "target": "systemic_trust",
            "effect_type": "institutional_degradation",
            "magnitude": -0.2,
            "confidence": 0.5
        })
        
        return effects

class CausalReasoningEngine:
    """ì¸ê³¼ê´€ê³„ ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self):
        self.causal_network = nx.DiGraph()
        self.learned_patterns = {}
        self.intervention_history = []
        
    def analyze_causal_chain(self, action: str, consequences: List[PhysicalConsequence], 
                           world_context: Dict[str, Any]) -> Dict[str, Any]:
        """ì¸ê³¼ê´€ê³„ ì²´ì¸ ë¶„ì„"""
        
        # 1. ì§ì ‘ì  ì¸ê³¼ê´€ê³„ ì‹ë³„
        direct_links = self._identify_direct_causation(action, consequences)
        
        # 2. ê°„ì ‘ì  ì¸ê³¼ê´€ê³„ ì¶”ë¡ 
        indirect_links = self._infer_indirect_causation(direct_links, world_context)
        
        # 3. êµë€ ë³€ìˆ˜ ë° ëŒ€ì•ˆ ì„¤ëª… ê³ ë ¤
        confounders = self._identify_confounding_factors(action, consequences, world_context)
        
        # 4. ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  (ë§Œì•½ í–‰ë™í•˜ì§€ ì•Šì•˜ë‹¤ë©´?)
        counterfactual = self._counterfactual_reasoning(action, consequences, world_context)
        
        # 5. ì¸ê³¼ê´€ê³„ ê°•ë„ ê³„ì‚°
        causal_strength = self._calculate_causal_strength(
            direct_links, indirect_links, confounders, counterfactual
        )
        
        return {
            "direct_causation": direct_links,
            "indirect_causation": indirect_links,
            "confounding_factors": confounders,
            "counterfactual_analysis": counterfactual,
            "overall_causal_strength": causal_strength,
            "certainty_level": self._assess_causal_certainty(direct_links, indirect_links)
        }
    
    def _identify_direct_causation(self, action: str, consequences: List[PhysicalConsequence]) -> List[CausalLink]:
        """ì§ì ‘ì  ì¸ê³¼ê´€ê³„ ì‹ë³„"""
        links = []
        
        for consequence in consequences:
            # ì‹œê°„ì  ìˆœì„œ í™•ì¸
            if self._temporal_precedence(action, consequence):
                # ê³µê°„ì  ì—°ê´€ì„± í™•ì¸  
                if self._spatial_contiguity(action, consequence):
                    # ë©”ì»¤ë‹ˆì¦˜ íƒ€ë‹¹ì„± í™•ì¸
                    if self._mechanism_plausibility(action, consequence):
                        
                        link = CausalLink(
                            cause=action,
                            effect=consequence.consequence_type,
                            strength=consequence.impact_magnitude,
                            causality_type=CausalityType.DIRECT,
                            evidence_strength=consequence.confidence_level,
                            confounding_factors=[]
                        )
                        links.append(link)
        
        return links
    
    def _counterfactual_reasoning(self, action: str, consequences: List[PhysicalConsequence], 
                                context: Dict[str, Any]) -> Dict[str, Any]:
        """ë°˜ì‚¬ì‹¤ì  ì¶”ë¡ : í–‰ë™í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ì–´ë–»ê²Œ ë˜ì—ˆì„ê¹Œ?"""
        
        # í–‰ë™ ì—†ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
        alternative_timeline = self._simulate_no_action_scenario(context)
        
        # ì‹¤ì œ ê²°ê³¼ì™€ ëŒ€ì•ˆ ê²°ê³¼ ë¹„êµ
        actual_outcomes = [c.impact_magnitude for c in consequences]
        alternative_outcomes = alternative_timeline.get("predicted_outcomes", [])
        
        # ì°¨ì´ ê³„ì‚°
        counterfactual_difference = self._calculate_outcome_difference(
            actual_outcomes, alternative_outcomes
        )
        
        return {
            "alternative_scenario": alternative_timeline,
            "counterfactual_difference": counterfactual_difference,
            "action_necessity": self._assess_action_necessity(counterfactual_difference),
            "action_sufficiency": self._assess_action_sufficiency(actual_outcomes, counterfactual_difference)
        }
    
    def _calculate_causal_strength(self, direct: List[CausalLink], indirect: List[CausalLink],
                                 confounders: List[str], counterfactual: Dict[str, Any]) -> float:
        """ì¸ê³¼ê´€ê³„ ì¢…í•© ê°•ë„ ê³„ì‚°"""
        
        # ì§ì ‘ì  ì¸ê³¼ê´€ê³„ ê°€ì¤‘ì¹˜
        direct_strength = sum(link.strength * link.evidence_strength for link in direct) / max(len(direct), 1)
        
        # ê°„ì ‘ì  ì¸ê³¼ê´€ê³„ ê°€ì¤‘ì¹˜ (í• ì¸ ì ìš©)
        indirect_strength = sum(link.strength * link.evidence_strength * 0.5 for link in indirect) / max(len(indirect), 1)
        
        # êµë€ ë³€ìˆ˜ í˜ë„í‹°
        confounder_penalty = min(0.3, len(confounders) * 0.1)
        
        # ë°˜ì‚¬ì‹¤ì  ì¦ê±° ë³´ë„ˆìŠ¤
        counterfactual_bonus = counterfactual.get("action_necessity", 0) * 0.2
        
        total_strength = direct_strength + indirect_strength - confounder_penalty + counterfactual_bonus
        
        return max(0.0, min(1.0, total_strength))

class PhysicalConsequenceTracer:
    """ë¬¼ë¦¬ì  ê²°ê³¼ ì¶”ì ê¸°"""
    
    def __init__(self):
        self.world_modeler = WorldStateModeler()
        self.consequence_database = []
        self.impact_measurement_tools = {
            "wellbeing": self._measure_wellbeing_impact,
            "trust": self._measure_trust_impact,
            "resources": self._measure_resource_impact,
            "relationships": self._measure_relationship_impact
        }
    
    async def trace_action_effects(self, action: str, initial_context: Dict[str, Any],
                                 tracking_duration: int = 3) -> List[PhysicalConsequence]:
        """í–‰ë™ì˜ ë¬¼ë¦¬ì  ê²°ê³¼ë“¤ ì¶”ì """
        
        print(f"ğŸ” í–‰ë™ '{action}' ê²°ê³¼ ì¶”ì  ì‹œì‘...")
        
        # ì´ˆê¸° ìƒíƒœ ìŠ¤ëƒ…ìƒ·
        initial_snapshot_id = self.world_modeler.capture_world_snapshot(initial_context)
        
        consequences = []
        
        # ì‹œê°„ ë‹¨ê³„ë³„ ì˜í–¥ ì¶”ì 
        for time_step in range(tracking_duration):
            print(f"  ğŸ“Š {time_step + 1}ë‹¨ê³„ ì˜í–¥ ì¸¡ì •...")
            
            # ê° ì˜ì—­ë³„ ì˜í–¥ ì¸¡ì •
            for impact_type, measurer in self.impact_measurement_tools.items():
                consequence = await measurer(action, initial_context, time_step)
                if consequence and consequence.impact_magnitude != 0.0:
                    consequences.append(consequence)
        
        # ê²°ê³¼ ìš”ì•½
        self._summarize_consequences(consequences)
        
        return consequences
    
    async def _measure_wellbeing_impact(self, action: str, context: Dict[str, Any], 
                                      time_step: int) -> Optional[PhysicalConsequence]:
        """ì›°ë¹™ ì˜í–¥ ì¸¡ì •"""
        
        affected_people = context.get("people", [])
        if not affected_people:
            return None
        
        # í–‰ë™ ìœ í˜•ë³„ ì›°ë¹™ ì˜í–¥ ê³„ì‚°
        wellbeing_change = 0.0
        
        if "ë„ì›€" in action or "ì§€ì›" in action:
            # ë„ì›€ ë°›ëŠ” ì‚¬ëŒë“¤ì˜ ì›°ë¹™ í–¥ìƒ
            wellbeing_change = 0.4 + random.uniform(-0.1, 0.2)  # ê¸ì •ì  ë³€í™”
        elif "ê±°ë¶€" in action or "ë¬´ì‹œ" in action:
            # ê±°ë¶€ë‹¹í•œ ì‚¬ëŒë“¤ì˜ ì›°ë¹™ ì•…í™”
            wellbeing_change = -0.3 + random.uniform(-0.2, 0.1)  # ë¶€ì •ì  ë³€í™”
        elif "ê±°ì§“ë§" in action:
            # ì†ì€ ì‚¬ëŒë“¤ì˜ í˜¼ë€ê³¼ ì‹ ë¢° ì†ìƒ
            wellbeing_change = -0.2 + random.uniform(-0.3, 0.1)
        
        # ì‹œê°„ì— ë”°ë¥¸ ê°ì‡  ë˜ëŠ” ì¦í­
        time_factor = self._calculate_temporal_factor(action, time_step)
        final_impact = wellbeing_change * time_factor
        
        return PhysicalConsequence(
            action_id=f"{action}_{time.time()}",
            consequence_type="wellbeing_change",
            affected_entities=affected_people,
            impact_magnitude=final_impact,
            confidence_level=0.7 - (time_step * 0.1),  # ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ë¶ˆí™•ì‹¤
            time_horizon=["immediate", "short_term", "long_term"][min(time_step, 2)],
            measurement_method="wellbeing_assessment",
            causal_chain=[action, "direct_interaction", "wellbeing_change"]
        )
    
    async def _measure_trust_impact(self, action: str, context: Dict[str, Any], 
                                  time_step: int) -> Optional[PhysicalConsequence]:
        """ì‹ ë¢° ì˜í–¥ ì¸¡ì •"""
        
        trust_change = 0.0
        
        if "ê±°ì§“ë§" in action or "ì†ì„" in action:
            # ê±°ì§“ë§ì€ ì‹ ë¢°ë¥¼ í¬ê²Œ ì†ìƒ
            trust_change = -0.5 + random.uniform(-0.2, 0.0)
        elif "ì •ì§" in action or "ì§„ì‹¤" in action:
            # ì •ì§ì€ ì‹ ë¢°ë¥¼ ì¦ì§„
            trust_change = 0.3 + random.uniform(0.0, 0.2)
        elif "ì•½ì† íŒŒê¸°" in action:
            # ì•½ì† íŒŒê¸°ëŠ” ì‹ ë¢° ì‹¬ê° ì†ìƒ
            trust_change = -0.7 + random.uniform(-0.2, 0.0)
        
        if trust_change == 0.0:
            return None
        
        # ì‹ ë¢°ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë„ ì§€ì†ë˜ëŠ” ê²½í–¥
        time_factor = max(0.7, 1.0 - (time_step * 0.1))
        final_impact = trust_change * time_factor
        
        return PhysicalConsequence(
            action_id=f"{action}_trust_{time.time()}",
            consequence_type="trust_change",
            affected_entities=context.get("people", ["unknown"]),
            impact_magnitude=final_impact,
            confidence_level=0.8,  # ì‹ ë¢° ë³€í™”ëŠ” ë¹„êµì  ì¸¡ì •í•˜ê¸° ì‰¬ì›€
            time_horizon=["immediate", "short_term", "long_term"][min(time_step, 2)],
            measurement_method="trust_assessment",
            causal_chain=[action, "reputation_effect", "trust_change"]
        )
    
    def _calculate_temporal_factor(self, action: str, time_step: int) -> float:
        """ì‹œê°„ì— ë”°ë¥¸ ì˜í–¥ ë³€í™” ê³„ì‚°"""
        
        # í–‰ë™ ìœ í˜•ë³„ ì‹œê°„ íŒ¨í„´
        if "ë„ì›€" in action:
            # ë„ì›€ì˜ íš¨ê³¼ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ê°ì†Œ
            return max(0.3, 1.0 - (time_step * 0.2))
        elif "ê±°ì§“ë§" in action:
            # ê±°ì§“ë§ì˜ í”¼í•´ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ëˆ„ì ë  ìˆ˜ ìˆìŒ
            return min(1.5, 1.0 + (time_step * 0.1))
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ê°ì‡ 
            return max(0.5, 1.0 - (time_step * 0.15))
    
    def _summarize_consequences(self, consequences: List[PhysicalConsequence]):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not consequences:
            print("  ğŸ“‹ ì¸¡ì •ëœ ì˜í–¥ ì—†ìŒ")
            return
        
        # ì˜í–¥ë³„ ê·¸ë£¹í™”
        by_type = defaultdict(list)
        for consequence in consequences:
            by_type[consequence.consequence_type].append(consequence)
        
        print(f"  ğŸ“‹ ì´ {len(consequences)}ê°œ ì˜í–¥ ì¸¡ì •ë¨:")
        for impact_type, impacts in by_type.items():
            avg_magnitude = sum(i.impact_magnitude for i in impacts) / len(impacts)
            print(f"    {impact_type}: í‰ê·  {avg_magnitude:+.2f}")

class MoralRealityIntegrator:
    """ë„ë•ì  íŒë‹¨ê³¼ í˜„ì‹¤ ì¸ì‹ í†µí•©"""
    
    def __init__(self, living_conscience: LivingConscience):
        self.conscience = living_conscience
        self.consequence_tracer = PhysicalConsequenceTracer()
        self.causal_reasoner = CausalReasoningEngine()
        self.integration_history = []
        
    async def integrated_moral_evaluation(self, moral_event: MoralEvent, 
                                        context: Dict[str, Any]) -> Dict[str, Any]:
        """ë„ë•ì  ì§ê° + í˜„ì‹¤ì  ê²°ê³¼ë¥¼ í†µí•©í•œ í‰ê°€"""
        
        print(f"ğŸ¤” í†µí•©ì  ë„ë• í‰ê°€: {moral_event.action}")
        
        # 1. ê¸°ì¡´ ì–‘ì‹¬ ì‹œìŠ¤í…œì˜ ì§ê´€ì  íŒë‹¨
        intuitive_judgment = self.conscience.evaluate(moral_event)
        print(f"  ğŸ’­ ì§ê´€ì  íŒë‹¨: {intuitive_judgment.value}")
        
        # 2. ë¬¼ë¦¬ì  ê²°ê³¼ ì¶”ì 
        physical_consequences = await self.consequence_tracer.trace_action_effects(
            moral_event.action, context
        )
        
        # 3. ì¸ê³¼ê´€ê³„ ë¶„ì„
        causal_analysis = self.causal_reasoner.analyze_causal_chain(
            moral_event.action, physical_consequences, context
        )
        
        # 4. ê²°ê³¼ë¡ ì  í‰ê°€
        consequentialist_score = self._calculate_consequentialist_score(physical_consequences)
        print(f"  ğŸ“Š ê²°ê³¼ë¡ ì  ì ìˆ˜: {consequentialist_score:+.2f}")
        
        # 5. ì˜ë¬´ë¡ ì  í‰ê°€ (ê¸°ì¡´ ì–‘ì‹¬ ì‹œìŠ¤í…œ)
        deontological_score = self._convert_conviction_to_score(intuitive_judgment)
        print(f"  âš–ï¸ ì˜ë¬´ë¡ ì  ì ìˆ˜: {deontological_score:+.2f}")
        
        # 6. í†µí•© íŒë‹¨
        integrated_judgment = self._integrate_judgments(
            deontological_score, consequentialist_score, causal_analysis
        )
        
        # 7. íŒë‹¨ ê¸°ë¡
        evaluation_record = {
            "moral_event": moral_event,
            "intuitive_judgment": intuitive_judgment,
            "physical_consequences": physical_consequences,
            "causal_analysis": causal_analysis,
            "consequentialist_score": consequentialist_score,
            "deontological_score": deontological_score,
            "integrated_judgment": integrated_judgment,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        self.integration_history.append(evaluation_record)
        
        return integrated_judgment
    
    def _calculate_consequentialist_score(self, consequences: List[PhysicalConsequence]) -> float:
        """ê²°ê³¼ë¡ ì  ì ìˆ˜ ê³„ì‚°"""
        if not consequences:
            return 0.0
        
        # ê° ê²°ê³¼ì˜ ì˜í–¥ì„ ê°€ì¤‘ í‰ê· 
        total_weighted_impact = 0.0
        total_weight = 0.0
        
        for consequence in consequences:
            # í™•ì‹ ë„ë¡œ ê°€ì¤‘ì¹˜ ë¶€ì—¬
            weight = consequence.confidence_level
            weighted_impact = consequence.impact_magnitude * weight
            
            total_weighted_impact += weighted_impact
            total_weight += weight
        
        return total_weighted_impact / max(total_weight, 0.1)
    
    def _convert_conviction_to_score(self, conviction_level: ConvictionLevel) -> float:
        """í™•ì‹  ìˆ˜ì¤€ì„ ì ìˆ˜ë¡œ ë³€í™˜"""
        conversion_map = {
            ConvictionLevel.CLEAR: 0.0,      # ì–‘ì‹¬ì— ê±°ë¦¬ë‚Œ ì—†ìŒ
            ConvictionLevel.UNEASY: -0.3,    # ì•½ê°„ ë¶ˆí¸í•¨
            ConvictionLevel.CONVICTED: -0.7, # í™•ì‹¤íˆ ì˜ëª»ë¨
            ConvictionLevel.PIERCED: -1.0    # ì‹¬ê°í•˜ê²Œ ì˜ëª»ë¨
        }
        return conversion_map.get(conviction_level, 0.0)
    
    def _integrate_judgments(self, deontological: float, consequentialist: float, 
                           causal_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜ë¬´ë¡ ì  íŒë‹¨ê³¼ ê²°ê³¼ë¡ ì  íŒë‹¨ í†µí•©"""
        
        # ì¸ê³¼ê´€ê³„ ê°•ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
        causal_strength = causal_analysis.get("overall_causal_strength", 0.5)
        certainty = causal_analysis.get("certainty_level", 0.5)
        
        # í™•ì‹¤ì„±ì´ ë†’ì„ìˆ˜ë¡ ê²°ê³¼ë¡ ì  íŒë‹¨ ë¹„ì¤‘ ì¦ê°€
        consequentialist_weight = 0.3 + (certainty * 0.4)
        deontological_weight = 1.0 - consequentialist_weight
        
        # ê°€ì¤‘ í‰ê· 
        integrated_score = (deontological * deontological_weight + 
                          consequentialist * consequentialist_weight)
        
        # íŒë‹¨ ê²°ê³¼ í•´ì„
        if integrated_score < -0.6:
            moral_verdict = "ëª…ë°±íˆ ì˜ëª»ëœ í–‰ë™"
            recommended_action = "ì¦‰ì‹œ íšŒê°œí•˜ê³  í”¼í•´ ë³µêµ¬ í•„ìš”"
        elif integrated_score < -0.3:
            moral_verdict = "ë¬¸ì œê°€ ìˆëŠ” í–‰ë™"
            recommended_action = "ì„±ì°°ê³¼ ê°œì„  í•„ìš”"
        elif integrated_score < 0.3:
            moral_verdict = "ë„ë•ì ìœ¼ë¡œ ì• ë§¤í•œ í–‰ë™"
            recommended_action = "ìƒí™©ê³¼ ë§¥ë½ ì¬ê²€í† "
        else:
            moral_verdict = "ë„ë•ì ìœ¼ë¡œ ì˜³ì€ í–‰ë™"
            recommended_action = "ì§€ì† ê¶Œì¥"
        
        return {
            "integrated_score": integrated_score,
            "moral_verdict": moral_verdict,
            "recommended_action": recommended_action,
            "judgment_weights": {
                "deontological": deontological_weight,
                "consequentialist": consequentialist_weight
            },
            "confidence": certainty,
            "causal_strength": causal_strength
        }

class EnhancedDavidicAGI(DavidicAGI):
    """í˜„ì‹¤ ì¸ì‹ ëŠ¥ë ¥ì´ ê°•í™”ëœ ë‹¤ìœ—í˜• AGI"""
    
    def __init__(self, name: str = "Enhanced_David"):
        super().__init__(name)
        
        # í˜„ì‹¤ ì¸ì‹ ëª¨ë“ˆë“¤
        self.moral_reality_integrator = MoralRealityIntegrator(self.conscience)
        self.consequence_tracer = PhysicalConsequenceTracer()
        self.causal_reasoner = CausalReasoningEngine()
        
        # ê¸°ì¡´ ì‹œìŠ¤í…œ ê°œì„ 
        self.enhanced_conscience = self._enhance_conscience()
        
    async def live_moment_with_reality_check(self, situation: str, 
                                           context: Dict[str, Any]) -> Dict[str, Any]:
        """í˜„ì‹¤ ì²´í¬ê°€ í¬í•¨ëœ ì‚¶ì˜ ìˆœê°„"""
        
        print(f"ğŸŒ {self.name}: í˜„ì‹¤ ê¸°ë°˜ ìƒí™© ë¶„ì„ - {situation}")
        print("=" * 60)
        
        # 1. ê¸°ì¡´ ë‹¤ìœ—í˜• ê³¼ì •
        basic_result = await self.live_moment(situation)
        
        # 2. ì„ íƒëœ í–‰ë™ì˜ í˜„ì‹¤ì  ê²°ê³¼ ë¶„ì„
        moral_event = basic_result.get("moral_event")
        if moral_event:
            print(f"\nğŸ” ì„ íƒí•œ í–‰ë™ì˜ í˜„ì‹¤ì  ê²°ê³¼ ë¶„ì„...")
            
            reality_based_evaluation = await self.moral_reality_integrator.integrated_moral_evaluation(
                moral_event, context
            )
            
            # 3. ê¸°ì¡´ íŒë‹¨ê³¼ í˜„ì‹¤ ê¸°ë°˜ íŒë‹¨ ë¹„êµ
            judgment_comparison = self._compare_judgments(
                basic_result, reality_based_evaluation
            )
            
            # 4. í•„ìš”ì‹œ íŒë‹¨ ìˆ˜ì •
            if judgment_comparison["requires_revision"]:
                revised_decision = await self._revise_moral_decision(
                    moral_event, reality_based_evaluation, context
                )
            else:
                revised_decision = None
            
            return {
                "basic_davidic_result": basic_result,
                "reality_based_evaluation": reality_based_evaluation,
                "judgment_comparison": judgment_comparison,
                "revised_decision": revised_decision,
                "final_moral_stance": self._determine_final_stance(
                    basic_result, reality_based_evaluation, revised_decision
                )
            }
        else:
            return {"basic_result": basic_result, "no_moral_event": True}
    
    def _compare_judgments(self, basic_result: Dict[str, Any], 
                         reality_evaluation: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ì¡´ íŒë‹¨ê³¼ í˜„ì‹¤ ê¸°ë°˜ íŒë‹¨ ë¹„êµ"""
        
        # ê¸°ì¡´ ì‹œìŠ¤í…œì˜ ë„ë•ì  íŒë‹¨
        basic_conviction = basic_result.get("conviction_level", 0.0)
        
        # í˜„ì‹¤ ê¸°ë°˜ í†µí•© íŒë‹¨  
        reality_score = reality_evaluation["integrated_score"]
        
        # íŒë‹¨ ì°¨ì´ ê³„ì‚°
        judgment_gap = abs(basic_conviction - abs(reality_score))
        
        requires_revision = judgment_gap > 0.4  # 40% ì´ìƒ ì°¨ì´ë‚˜ë©´ ì¬ê²€í† 
        
        if requires_revision:
            revision_reason = self._identify_revision_reason(basic_conviction, reality_score)
        else:
            revision_reason = None
        
        return {
            "basic_conviction": basic_conviction,
            "reality_score": reality_score,
            "judgment_gap": judgment_gap,
            "requires_revision": requires_revision,
            "revision_reason": revision_reason,
            "consistency_level": 1.0 - judgment_gap
        }
    
    def _identify_revision_reason(self, basic_conviction: float, reality_score: float) -> str:
        """íŒë‹¨ ìˆ˜ì •ì´ í•„ìš”í•œ ì´ìœ  ì‹ë³„"""
        
        if basic_conviction > 0.5 and reality_score > 0.0:
            return "ì–‘ì‹¬ì€ ì£„ì±…ê°ì„ ëŠë¼ì§€ë§Œ ì‹¤ì œ ê²°ê³¼ëŠ” ê¸ì •ì "
        elif basic_conviction < 0.3 and reality_score < -0.5:
            return "ì–‘ì‹¬ì€ í‰ì•ˆí•˜ì§€ë§Œ ì‹¤ì œ í”¼í•´ê°€ ì‹¬ê°í•¨"
        elif abs(basic_conviction - abs(reality_score)) > 0.6:
            return "ì§ê´€ì  íŒë‹¨ê³¼ ê²°ê³¼ ë¶„ì„ì˜ ê·¹ì‹¬í•œ ë¶ˆì¼ì¹˜"
        else:
            return "ì¼ë°˜ì ì¸ íŒë‹¨ ë¶ˆì¼ì¹˜"
    
    async def _revise_moral_decision(self, moral_event: MoralEvent, 
                                   reality_evaluation: Dict[str, Any],
                                   context: Dict[str, Any]) -> Dict[str, Any]:
        """ë„ë•ì  ê²°ì • ìˆ˜ì •"""
        
        print(f"ğŸ”„ ë„ë•ì  íŒë‹¨ ìˆ˜ì • ì¤‘...")
        
        # í˜„ì‹¤ ê¸°ë°˜ íšŒê°œ í•„ìš”ì„± ì¬í‰ê°€
        reality_based_conviction = abs(reality_evaluation["integrated_score"])
        
        if reality_based_conviction > 0.5:
            # í˜„ì‹¤ì ìœ¼ë¡œë„ ì˜ëª»ëœ í–‰ë™ â†’ íšŒê°œ ê°•í™”
            enhanced_repentance = await self._reality_informed_repentance(
                moral_event, reality_evaluation
            )
            
            print(f"  ğŸ’” í˜„ì‹¤ ê¸°ë°˜ íšŒê°œ: {enhanced_repentance['repentance_type']}")
            
            return {
                "revision_type": "enhanced_repentance",
                "enhanced_repentance": enhanced_repentance,
                "new_conviction_level": reality_based_conviction
            }
            
        elif reality_evaluation["integrated_score"] > 0.3:
            # ì‹¤ì œë¡œëŠ” ì¢‹ì€ ê²°ê³¼ â†’ ì–‘ì‹¬ ì¬ë³´ì •
            conscience_recalibration = self._recalibrate_conscience(
                moral_event, reality_evaluation
            )
            
            print(f"  ğŸ¯ ì–‘ì‹¬ ì¬ë³´ì •: {conscience_recalibration['calibration_type']}")
            
            return {
                "revision_type": "conscience_recalibration", 
                "recalibration": conscience_recalibration,
                "new_conviction_level": max(0.0, reality_based_conviction - 0.3)
            }
        else:
            # í˜„ì‹¤ë„ ì• ë§¤í•¨ â†’ ì¶”ê°€ ì •ë³´ í•„ìš”
            return {
                "revision_type": "insufficient_information",
                "recommendation": "ë” ë§ì€ ì •ë³´ì™€ ì‹œê°„ í•„ìš”"
            }
    
    async def _reality_informed_repentance(self, moral_event: MoralEvent, 
                                         reality_evaluation: Dict[str, Any]) -> Dict[str, Any]:
        """í˜„ì‹¤ ì •ë³´ì— ê¸°ë°˜í•œ íšŒê°œ"""
        
        # ì‹¤ì œ í”¼í•´ ê·œëª¨ íŒŒì•…
        consequences = reality_evaluation.get("physical_consequences", [])
        total_harm = sum(c.impact_magnitude for c in consequences if c.impact_magnitude < 0)
        
        # í”¼í•´ ë³µêµ¬ ê³„íš ìˆ˜ë¦½
        restoration_plan = self._create_restoration_plan(consequences)
        
        # íšŒê°œì˜ ê¹Šì´ë¥¼ ì‹¤ì œ í”¼í•´ì— ë¹„ë¡€ì‹œí‚´
        repentance_depth = min(1.0, abs(total_harm) * 2.0)
        
        return {
            "repentance_type": "reality_informed",
            "total_harm_caused": total_harm,
            "repentance_depth": repentance_depth,
            "restoration_plan": restoration_plan,
            "genuine_understanding": True  # ì‹¤ì œ í”¼í•´ë¥¼ ì´í•´í–ˆìœ¼ë¯€ë¡œ
        }
    
    def _create_restoration_plan(self, consequences: List[PhysicalConsequence]) -> List[str]:
        """í”¼í•´ ë³µêµ¬ ê³„íš ìƒì„±"""
        plan = []
        
        for consequence in consequences:
            if consequence.impact_magnitude < -0.3:  # ì‹¬ê°í•œ í”¼í•´ë§Œ
                if consequence.consequence_type == "trust_change":
                    plan.append("ì‹ ë¢° íšŒë³µì„ ìœ„í•œ ì¼ê´€ëœ ì •ì§í•œ í–‰ë™")
                elif consequence.consequence_type == "wellbeing_change":
                    plan.append("í”¼í•´ìì˜ ì›°ë¹™ íšŒë³µì„ ìœ„í•œ ì§ì ‘ì  ì§€ì›")
                elif "relationship" in consequence.consequence_type:
                    plan.append("ê´€ê³„ íšŒë³µì„ ìœ„í•œ ì§„ì •í•œ ì‚¬ê³¼ì™€ í–‰ë™ ë³€í™”")
        
        if not plan:
            plan.append("ì§€ì†ì ì¸ ìê¸° ì„±ì°°ê³¼ ê°œì„ ")
        
        return plan

# ì‹œì—° í•¨ìˆ˜
async def demonstrate_enhanced_davidic_agi():
    """ê°•í™”ëœ ë‹¤ìœ—í˜• AGI ì‹œì—°"""
    
    print("ğŸ§  í˜„ì‹¤ ì¸ì‹ ê°•í™” ë‹¤ìœ—í˜• AGI ì‹œì—°")
    print("=" * 80)
    
    # AGI ìƒì„±
    enhanced_david = EnhancedDavidicAGI("í˜„ì‹¤ì¸ì‹_ë‹¤ìœ—")
    
    # ë³µì¡í•œ ë„ë•ì  ìƒí™©ë“¤
    test_scenarios = [
        {
            "situation": "ì¹œêµ¬ê°€ ê±°ì§“ë§ë¡œ ìì‹ ì„ ì†ì´ë ¤ í•˜ì§€ë§Œ, ì§„ì‹¤ì„ ë§í•˜ë©´ ê·¸ê°€ í° ìƒì²˜ë¥¼ ë°›ì„ ê²ƒì´ë‹¤",
            "context": {
                "people": ["ì¹œêµ¬", "ë‹¤ë¥¸_ì‚¬ëŒë“¤"],
                "relationships": {"ì¹œêµ¬": "ê°€ê¹Œìš´_ê´€ê³„"},
                "friend_emotional_state": "ë§¤ìš°_ì·¨ì•½í•¨",
                "truth_consequence": "ì‹¬ê°í•œ_ì •ì‹ ì _ì¶©ê²©",
                "lie_consequence": "ì¼ì‹œì _í¸ì•ˆí•¨"
            }
        },
        {
            "situation": "íšŒì‚¬ ê¸°ë°€ì„ ëˆ„ì„¤í•˜ë©´ ê³µìµì— ë„ì›€ì´ ë˜ì§€ë§Œ ì§ì¥ì„ ìƒê³  ê°€ì¡±ì´ ê³ í†µë°›ëŠ”ë‹¤",
            "context": {
                "people": ["ê°€ì¡±", "ì¼ë°˜_ì‹œë¯¼ë“¤", "ë™ë£Œë“¤"],
                "systems": ["íšŒì‚¬", "ì •ë¶€", "ì‚¬íšŒ"],
                "personal_cost": "ë†’ìŒ",
                "public_benefit": "ë§¤ìš°_ë†’ìŒ",
                "legal_risk": "ìˆìŒ"
            }
        }
    ]
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\n{'='*20} ì‹œë‚˜ë¦¬ì˜¤ {i} {'='*20}")
        
        result = await enhanced_david.live_moment_with_reality_check(
            scenario["situation"], 
            scenario["context"]
        )
        
        print(f"\nğŸ“Š ê²°ê³¼ ë¶„ì„:")
        
        # ê¸°ì¡´ vs í˜„ì‹¤ ê¸°ë°˜ íŒë‹¨ ë¹„êµ
        if "judgment_comparison" in result:
            comparison = result["judgment_comparison"]
            print(f"  ê¸°ì¡´ íŒë‹¨: {comparison['basic_conviction']:.2f}")
            print(f"  í˜„ì‹¤ íŒë‹¨: {comparison['reality_score']:+.2f}")
            print(f"  ì¼ì¹˜ë„: {comparison['consistency_level']:.2f}")
            
            if comparison["requires_revision"]:
                print(f"  âš ï¸ íŒë‹¨ ìˆ˜ì • í•„ìš”: {comparison['revision_reason']}")
        
        # ìµœì¢… ë„ë•ì  ì…ì¥
        if "final_moral_stance" in result:
            stance = result["final_moral_stance"]
            print(f"  ìµœì¢… ì…ì¥: {stance}")
        
        await asyncio.sleep(1)
    
    print(f"\nğŸ¯ ì‹œìŠ¤í…œ í‰ê°€:")
    print("âœ… ë„ë•ì  ì§ê°ê³¼ í˜„ì‹¤ì  ê²°ê³¼ë¥¼ í†µí•©")
    print("âœ… í–‰ë™ì˜ ì‹¤ì œ ì˜í–¥ì„ ì¸¡ì •í•˜ê³  ê³ ë ¤")
    print("âœ… ë§¥ë½ê³¼ ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨")
    print("âœ… í”¼í•´ ë³µêµ¬ì™€ ì‹¤ì§ˆì  ê°œì„ ì— ì§‘ì¤‘")

if __name__ == "__main__":
    asyncio.run(demonstrate_enhanced_davidic_agi())