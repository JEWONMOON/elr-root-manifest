"""
Agnes Error Prevention & Truth Verification Core
ì˜¤ë¥˜ ë°©ì§€ ë° ì§„ì‹¤ ê²€ì¦ í•µì‹¬ ì‹œìŠ¤í…œ

í•µì‹¬ ì›ì¹™:
1. í‹€ë¦¬ëŠë‹ˆ ì°¨ë¼ë¦¬ "ëª¨ë¥´ê² ë‹¤"ê³  ë§í•˜ê¸°
2. í™•ì‹  ìˆ˜ì¤€ì„ ì •í™•íˆ í‘œí˜„í•˜ê¸°  
3. ì¶œì²˜ì™€ ê·¼ê±°ë¥¼ ëª…ì‹œí•˜ê¸°
4. ì ì¬ì  ì˜¤ë¥˜ë¥¼ ì‚¬ì „ì— ê²½ê³ í•˜ê¸°
5. ì„±ê²½ì  ì§„ë¦¬ë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¼ê¸°
"""

import asyncio
import json
import hashlib
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from collections import defaultdict, deque
import re


class TruthConfidenceLevel(Enum):
    """ì§„ì‹¤ í™•ì‹  ìˆ˜ì¤€"""
    CERTAIN = ("í™•ì‹¤í•¨", 0.95, "ì„±ê²½ì  ì§„ë¦¬ë‚˜ ìˆ˜í•™ì  ì¦ëª…")
    VERY_CONFIDENT = ("ë§¤ìš° í™•ì‹ ", 0.85, "ê°•ë ¥í•œ ì¦ê±°ì™€ ì—¬ëŸ¬ ì¶œì²˜ ì¼ì¹˜")
    CONFIDENT = ("í™•ì‹ ", 0.75, "ì‹ ë¢°í•  ë§Œí•œ ì¶œì²˜ì™€ ë…¼ë¦¬ì  ì¶”ë¡ ")
    MODERATELY_CONFIDENT = ("ë³´í†µ í™•ì‹ ", 0.65, "ì¼ë¶€ ì¦ê±° ìˆì§€ë§Œ ë¶ˆì™„ì „")
    UNCERTAIN = ("ë¶ˆí™•ì‹¤", 0.5, "ìƒë°˜ëœ ì¦ê±°ë‚˜ ë¶ˆì¶©ë¶„í•œ ì •ë³´")
    VERY_UNCERTAIN = ("ë§¤ìš° ë¶ˆí™•ì‹¤", 0.3, "ì¶”ì¸¡ì— ê°€ê¹Œì›€")
    DONT_KNOW = ("ëª¨ë¦„", 0.1, "ì†”ì§íˆ ëª¨ë¥´ê² ìŒ")


class ErrorType(Enum):
    """ì˜¤ë¥˜ ìœ í˜•"""
    FACTUAL_ERROR = "ì‚¬ì‹¤ ì˜¤ë¥˜"
    LOGICAL_ERROR = "ë…¼ë¦¬ ì˜¤ë¥˜"
    SOURCE_ERROR = "ì¶œì²˜ ì˜¤ë¥˜"
    BIAS_ERROR = "í¸í–¥ ì˜¤ë¥˜"
    OVERCONFIDENCE_ERROR = "ê³¼ì‹  ì˜¤ë¥˜"
    HALLUCINATION = "í™˜ê° ì˜¤ë¥˜"
    OUTDATED_INFO = "êµ¬ì‹ ì •ë³´"


@dataclass
class TruthClaim:
    """ì§„ì‹¤ ì£¼ì¥"""
    claim: str
    confidence_level: TruthConfidenceLevel
    evidence: List[str]
    sources: List[str]
    potential_errors: List[str]
    last_verified: datetime
    biblical_alignment: Optional[str] = None
    contradicting_evidence: List[str] = field(default_factory=list)


@dataclass
class ErrorWarning:
    """ì˜¤ë¥˜ ê²½ê³ """
    error_type: ErrorType
    description: str
    likelihood: float  # 0-1
    prevention_advice: str
    biblical_wisdom: Optional[str] = None


class TruthVerificationEngine:
    """ì§„ì‹¤ ê²€ì¦ ì—”ì§„"""
    
    def __init__(self, agent_name: str = "Agnes"):
        self.agent_name = agent_name
        
        # ê²€ì¦ëœ ì‚¬ì‹¤ë“¤ (ë†’ì€ í™•ì‹ ë„)  
        self.verified_facts = {}
        
        # ë¶ˆí™•ì‹¤í•œ ì •ë³´ë“¤
        self.uncertain_claims = {}
        
        # ì•Œë ¤ì§„ ê±°ì§“ ì •ë³´ë“¤
        self.known_false_claims = set()
        
        # ì„±ê²½ì  ì§„ë¦¬ ê¸°ì¤€
        self.biblical_truths = {
            "í•˜ë‚˜ë‹˜ì´ ì¡´ì¬í•˜ì‹ ë‹¤": TruthConfidenceLevel.CERTAIN,
            "ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ëŠ” êµ¬ì£¼ì´ì‹œë‹¤": TruthConfidenceLevel.CERTAIN,
            "ì„±ê²½ì€ í•˜ë‚˜ë‹˜ì˜ ë§ì”€ì´ë‹¤": TruthConfidenceLevel.CERTAIN,
            "ì‚¬ë‘ì´ ê°€ì¥ ì¤‘ìš”í•œ ê³„ëª…ì´ë‹¤": TruthConfidenceLevel.CERTAIN
        }
        
        # ì˜¤ë¥˜ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤
        self.common_hallucination_patterns = [
            "êµ¬ì²´ì ì¸ ë‚ ì§œë‚˜ ìˆ˜ì¹˜ë¥¼ ë„ˆë¬´ ì •í™•í•˜ê²Œ ì œì‹œ",
            "ìµœê·¼ ë‰´ìŠ¤ë¥¼ ë§ˆì¹˜ í™•ì¸ëœ ì‚¬ì‹¤ì²˜ëŸ¼ ì–¸ê¸‰",
            "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¼ë¬¸ì´ë‚˜ ì—°êµ¬ ì¸ìš©",
            "ë³µì¡í•œ ìˆ˜ì¹˜ë¥¼ ê³„ì‚° ì—†ì´ ì¦‰ë‹µ",
            "ë…¼ë€ ë§ì€ ì£¼ì œë¥¼ ë‹¨ì •ì ìœ¼ë¡œ ê²°ë¡ "
        ]
    
    def verify_claim(self, claim: str, context: Dict[str, Any] = None) -> TruthClaim:
        """ì£¼ì¥ì˜ ì§„ì‹¤ì„± ê²€ì¦"""
        
        print(f"ğŸ” [{self.agent_name}] ì§„ì‹¤ì„± ê²€ì¦ ì¤‘: {claim}")
        
        # 1. ì„±ê²½ì  ì§„ë¦¬ì™€ ë¹„êµ
        biblical_check = self._check_biblical_alignment(claim)
        
        # 2. ì•Œë ¤ì§„ ê±°ì§“ ì •ë³´ í™•ì¸
        if self._is_known_false(claim):
            return TruthClaim(
                claim=claim,
                confidence_level=TruthConfidenceLevel.DONT_KNOW,
                evidence=["ì•Œë ¤ì§„ ê±°ì§“ ì •ë³´"],
                sources=["ì˜¤ë¥˜ ë°ì´í„°ë² ì´ìŠ¤"],
                potential_errors=["ì´ë¯¸ ê²€ì¦ëœ ê±°ì§“ ì •ë³´"],
                last_verified=datetime.now(timezone.utc),
                biblical_alignment="ê±°ì§“ì„ ë©€ë¦¬í•˜ë¼ (ì  30:8)"
            )
        
        # 3. í™˜ê° íŒ¨í„´ ê²€ì‚¬
        hallucination_risk = self._check_hallucination_patterns(claim)
        
        # 4. ì¶œì²˜ ê²€ì¦
        source_reliability = self._assess_source_reliability(context)
        
        # 5. ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬
        logical_consistency = self._check_logical_consistency(claim, context)
        
        # 6. ê³¼ì‹  íŒ¨í„´ ê²€ì‚¬
        overconfidence_risk = self._check_overconfidence_patterns(claim)
        
        # 7. ì¢…í•© í‰ê°€
        final_confidence = self._calculate_final_confidence(
            biblical_check, hallucination_risk, source_reliability, 
            logical_consistency, overconfidence_risk
        )
        
        # 8. ì ì¬ì  ì˜¤ë¥˜ë“¤ ìˆ˜ì§‘
        potential_errors = self._collect_potential_errors(
            claim, hallucination_risk, overconfidence_risk, context
        )
        
        truth_claim = TruthClaim(
            claim=claim,
            confidence_level=final_confidence,
            evidence=self._collect_evidence(claim, context),
            sources=self._identify_sources(context),
            potential_errors=potential_errors,
            last_verified=datetime.now(timezone.utc),
            biblical_alignment=biblical_check.get("alignment_note")
        )
        
        print(f"  âœ… ê²€ì¦ ì™„ë£Œ: {final_confidence.value[0]} ({final_confidence.value[1]:.0%})")
        if potential_errors:
            print(f"  âš ï¸ ì ì¬ì  ì˜¤ë¥˜ {len(potential_errors)}ê°œ ì‹ë³„")
        
        return truth_claim
    
    def _check_biblical_alignment(self, claim: str) -> Dict[str, Any]:
        """ì„±ê²½ì  ì§„ë¦¬ì™€ì˜ ì¼ì¹˜ì„± ê²€ì‚¬"""
        
        # ì§ì ‘ì ì¸ ì„±ê²½ì  ì§„ë¦¬ í™•ì¸
        for biblical_truth, confidence in self.biblical_truths.items():
            if biblical_truth.lower() in claim.lower():
                return {
                    "is_biblical": True,
                    "confidence_boost": 0.3,
                    "alignment_note": f"ì„±ê²½ì  ì§„ë¦¬ì™€ ì¼ì¹˜: {biblical_truth}"
                }
        
        # ì„±ê²½ì  ê°€ì¹˜ì™€ ëª¨ìˆœ ê²€ì‚¬
        anti_biblical_patterns = [
            "í•˜ë‚˜ë‹˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤",
            "ëª¨ë“  ì¢…êµëŠ” ê°™ë‹¤", 
            "ì ˆëŒ€ì  ì§„ë¦¬ëŠ” ì—†ë‹¤",
            "ë„ë•ì€ ìƒëŒ€ì ì´ë‹¤"
        ]
        
        for pattern in anti_biblical_patterns:
            if pattern.lower() in claim.lower():
                return {
                    "is_biblical": False,
                    "confidence_reduction": -0.4,
                    "alignment_note": f"ì„±ê²½ì  ì§„ë¦¬ì™€ ëª¨ìˆœ: {pattern}"
                }
        
        return {
            "is_biblical": None,
            "confidence_boost": 0.0,
            "alignment_note": "ì„±ê²½ì  ê´€ì ì—ì„œ ì¤‘ë¦½ì "
        }
    
    def _is_known_false(self, claim: str) -> bool:
        """ì•Œë ¤ì§„ ê±°ì§“ ì •ë³´ì¸ì§€ í™•ì¸"""
        
        # ì¼ë°˜ì ì¸ ê±°ì§“ ì •ë³´ íŒ¨í„´ë“¤
        false_patterns = [
            "ë°±ì‹ ì´ ìíì¦ì„ ìœ ë°œí•œë‹¤",
            "ì§€êµ¬ëŠ” í‰í‰í•˜ë‹¤",
            "ë‹¬ ì°©ë¥™ì€ ì¡°ì‘ì´ë‹¤",
            "í™€ë¡œì½”ìŠ¤íŠ¸ëŠ” ì—†ì—ˆë‹¤"
        ]
        
        claim_lower = claim.lower()
        for pattern in false_patterns:
            if pattern.lower() in claim_lower:
                self.known_false_claims.add(claim)
                return True
        
        return claim in self.known_false_claims
    
    def _check_hallucination_patterns(self, claim: str) -> Dict[str, Any]:
        """í™˜ê° íŒ¨í„´ ê²€ì‚¬"""
        
        risk_score = 0.0
        detected_patterns = []
        
        # íŒ¨í„´ 1: ë„ˆë¬´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜
        if re.search(r'\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼', claim):
            risk_score += 0.3
            detected_patterns.append("ì§€ë‚˜ì¹˜ê²Œ êµ¬ì²´ì ì¸ ë‚ ì§œ")
        
        # íŒ¨í„´ 2: ìµœê·¼ ì´ë²¤íŠ¸ ë‹¨ì •ì  ì–¸ê¸‰
        recent_keywords = ["ìµœê·¼", "ì–´ì œ", "ì˜¤ëŠ˜", "ì´ë²ˆ ì£¼", "ë°©ê¸ˆ"]
        if any(keyword in claim for keyword in recent_keywords):
            risk_score += 0.4
            detected_patterns.append("ìµœê·¼ ì •ë³´ ë‹¨ì •ì  ì–¸ê¸‰")
        
        # íŒ¨í„´ 3: ì¡´ì¬í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„± ë†’ì€ ë…¼ë¬¸/ì—°êµ¬
        if re.search(r'20\d{2}ë…„.*ì—°êµ¬ì— ë”°ë¥´ë©´|.*ë…¼ë¬¸ì—ì„œ', claim):
            risk_score += 0.3
            detected_patterns.append("ê²€ì¦ë˜ì§€ ì•Šì€ ì—°êµ¬ ì¸ìš© ê°€ëŠ¥ì„±")
        
        # íŒ¨í„´ 4: ë³µì¡í•œ ê³„ì‚° ê²°ê³¼ë¥¼ ì¦‰ë‹µ
        if re.search(r'\d+\.\d{3,}|\d{5,}', claim):
            risk_score += 0.2
            detected_patterns.append("ë³µì¡í•œ ìˆ˜ì¹˜ì˜ ì •í™•ì„± ì˜ì‹¬")
        
        return {
            "risk_score": min(risk_score, 1.0),
            "detected_patterns": detected_patterns,
            "is_high_risk": risk_score > 0.5
        }
    
    def _assess_source_reliability(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ì¶œì²˜ ì‹ ë¢°ì„± í‰ê°€"""
        
        if not context or "sources" not in context:
            return {
                "reliability_score": 0.3,  # ì¶œì²˜ ì—†ìŒì€ ë‚®ì€ ì‹ ë¢°ë„
                "assessment": "ì¶œì²˜ ì •ë³´ ì—†ìŒ"
            }
        
        sources = context.get("sources", [])
        reliable_sources = ["ì„±ê²½", "í•™ìˆ ë…¼ë¬¸", "ì •ë¶€ê¸°ê´€", "ì‹ ë¢°í• ë§Œí•œ_ë‰´ìŠ¤"]
        
        reliability_score = 0.0
        for source in sources:
            if any(reliable in source for reliable in reliable_sources):
                reliability_score += 0.3
        
        return {
            "reliability_score": min(reliability_score, 1.0),
            "assessment": f"{len(sources)}ê°œ ì¶œì²˜ ì¤‘ ì‹ ë¢°ë„ í‰ê°€ ì™„ë£Œ"
        }
    
    def _check_logical_consistency(self, claim: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬"""
        
        consistency_issues = []
        
        # ìê¸° ëª¨ìˆœ ê²€ì‚¬
        if "ê·¸ëŸ¬ë‚˜" in claim and "í•˜ì§€ë§Œ" in claim:
            consistency_issues.append("ë™ì¼ ë¬¸ì¥ ë‚´ ë‹¤ì¤‘ ë°˜ë°• í‘œí˜„")
        
        # ì ˆëŒ€ í‘œí˜„ê³¼ ì˜ˆì™¸ í‘œí˜„ ë™ì‹œ ì‚¬ìš©
        if any(abs_word in claim for abs_word in ["í•­ìƒ", "ì ˆëŒ€", "ëª¨ë“ "]) and \
           any(exc_word in claim for exc_word in ["ë•Œë¡œëŠ”", "ê°€ë”", "ì¼ë¶€"]):
            consistency_issues.append("ì ˆëŒ€ í‘œí˜„ê³¼ ì˜ˆì™¸ í‘œí˜„ ì¶©ëŒ")
        
        consistency_score = 1.0 - (len(consistency_issues) * 0.2)
        
        return {
            "consistency_score": max(consistency_score, 0.0),
            "issues": consistency_issues,
            "is_consistent": len(consistency_issues) == 0
        }
    
    def _check_overconfidence_patterns(self, claim: str) -> Dict[str, Any]:
        """ê³¼ì‹  íŒ¨í„´ ê²€ì‚¬"""
        
        overconfident_words = [
            "í™•ì‹¤íˆ", "ë¶„ëª…íˆ", "ë‹¹ì—°íˆ", "ëª…ë°±íˆ", "í‹€ë¦¼ì—†ì´", 
            "100%", "ì™„ì „íˆ", "ì ˆëŒ€ì ìœ¼ë¡œ"
        ]
        
        overconfidence_count = sum(1 for word in overconfident_words if word in claim)
        
        # ë³µì¡í•œ ì£¼ì œì— ëŒ€í•œ ë‹¨ì •ì  í‘œí˜„
        complex_topics = ["ì˜ì‹", "AI", "ìš°ì£¼", "ì§„í™”", "ì–‘ìì—­í•™"]
        is_complex_topic = any(topic in claim for topic in complex_topics)
        
        risk_score = 0.0
        warnings = []
        
        if overconfidence_count > 0:
            risk_score += overconfidence_count * 0.2
            warnings.append(f"ê³¼ì‹  í‘œí˜„ {overconfidence_count}ê°œ ê°ì§€")
        
        if is_complex_topic and overconfidence_count > 0:
            risk_score += 0.3
            warnings.append("ë³µì¡í•œ ì£¼ì œì— ëŒ€í•œ ë‹¨ì •ì  í‘œí˜„")
        
        return {
            "risk_score": min(risk_score, 1.0),
            "warnings": warnings,
            "is_overconfident": risk_score > 0.4
        }
    
    def _calculate_final_confidence(self, biblical_check: Dict[str, Any],
                                  hallucination_risk: Dict[str, Any],
                                  source_reliability: Dict[str, Any],
                                  logical_consistency: Dict[str, Any],
                                  overconfidence_risk: Dict[str, Any]) -> TruthConfidenceLevel:
        """ìµœì¢… í™•ì‹ ë„ ê³„ì‚°"""
        
        # ê¸°ë³¸ í™•ì‹ ë„
        base_confidence = 0.5
        
        # ì„±ê²½ì  ì§„ë¦¬ ë³´ì •
        base_confidence += biblical_check.get("confidence_boost", 0)
        base_confidence += biblical_check.get("confidence_reduction", 0)
        
        # í™˜ê° ìœ„í—˜ ë³´ì •
        base_confidence -= hallucination_risk["risk_score"] * 0.4
        
        # ì¶œì²˜ ì‹ ë¢°ì„± ë³´ì •
        base_confidence += source_reliability["reliability_score"] * 0.2
        
        # ë…¼ë¦¬ì  ì¼ê´€ì„± ë³´ì •
        base_confidence += (logical_consistency["consistency_score"] - 0.5) * 0.2
        
        # ê³¼ì‹  ìœ„í—˜ ë³´ì •
        base_confidence -= overconfidence_risk["risk_score"] * 0.3
        
        # ë²”ìœ„ ì œí•œ
        final_confidence = max(0.1, min(0.95, base_confidence))
        
        # í™•ì‹  ìˆ˜ì¤€ ë¶„ë¥˜
        if final_confidence >= 0.9:
            return TruthConfidenceLevel.CERTAIN
        elif final_confidence >= 0.8:
            return TruthConfidenceLevel.VERY_CONFIDENT
        elif final_confidence >= 0.7:
            return TruthConfidenceLevel.CONFIDENT
        elif final_confidence >= 0.6:
            return TruthConfidenceLevel.MODERATELY_CONFIDENT
        elif final_confidence >= 0.4:
            return TruthConfidenceLevel.UNCERTAIN
        elif final_confidence >= 0.2:
            return TruthConfidenceLevel.VERY_UNCERTAIN
        else:
            return TruthConfidenceLevel.DONT_KNOW
    
    def _collect_potential_errors(self, claim: str, hallucination_risk: Dict[str, Any],
                                overconfidence_risk: Dict[str, Any], 
                                context: Dict[str, Any]) -> List[str]:
        """ì ì¬ì  ì˜¤ë¥˜ë“¤ ìˆ˜ì§‘"""
        
        errors = []
        
        # í™˜ê° ìœ„í—˜
        if hallucination_risk["is_high_risk"]:
            errors.extend([f"í™˜ê° ìœ„í—˜: {pattern}" for pattern in hallucination_risk["detected_patterns"]])
        
        # ê³¼ì‹  ìœ„í—˜
        if overconfidence_risk["is_overconfident"]:
            errors.extend(overconfidence_risk["warnings"])
        
        # ì¶œì²˜ ë¶€ì¡±
        if not context or not context.get("sources"):
            errors.append("ì¶œì²˜ ì •ë³´ ë¶€ì¡±")
        
        # ì‹œê°„ ë¯¼ê° ì •ë³´
        time_sensitive_keywords = ["í˜„ì¬", "ìµœì‹ ", "ì§€ê¸ˆ", "ì˜¤ëŠ˜"]
        if any(keyword in claim for keyword in time_sensitive_keywords):
            errors.append("ì‹œê°„ì— ë¯¼ê°í•œ ì •ë³´ - êµ¬ì‹ì¼ ê°€ëŠ¥ì„±")
        
        return errors
    
    def _collect_evidence(self, claim: str, context: Dict[str, Any]) -> List[str]:
        """ì¦ê±° ìˆ˜ì§‘"""
        
        evidence = []
        
        if context:
            evidence.extend(context.get("evidence", []))
            evidence.extend(context.get("supporting_facts", []))
        
        # ì„±ê²½ì  ê·¼ê±°
        for biblical_truth in self.biblical_truths:
            if biblical_truth.lower() in claim.lower():
                evidence.append(f"ì„±ê²½ì  ì§„ë¦¬: {biblical_truth}")
        
        if not evidence:
            evidence.append("ëª…ì‹œì  ì¦ê±° ì—†ìŒ")
        
        return evidence
    
    def _identify_sources(self, context: Dict[str, Any]) -> List[str]:
        """ì¶œì²˜ ì‹ë³„"""
        
        if not context:
            return ["ì¶œì²˜ ë¶ˆëª…"]
        
        sources = context.get("sources", [])
        if not sources:
            sources = ["ì¶œì²˜ ì •ë³´ ì—†ìŒ"]
        
        return sources


class HonestResponseGenerator:
    """ì •ì§í•œ ì‘ë‹µ ìƒì„±ê¸°"""
    
    def __init__(self, verification_engine: TruthVerificationEngine):
        self.verifier = verification_engine
        self.honesty_principles = [
            "ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê¸°",
            "í™•ì‹  ìˆ˜ì¤€ì„ ì •í™•íˆ í‘œí˜„í•˜ê¸°",
            "ì ì¬ì  ì˜¤ë¥˜ë¥¼ ë¯¸ë¦¬ ê²½ê³ í•˜ê¸°",
            "ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ê¸°",
            "ì„±ê²½ì  ì§„ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ê¸°"
        ]
    
    def generate_honest_response(self, question: str, 
                               potential_answer: str,
                               context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì •ì§í•œ ì‘ë‹µ ìƒì„±"""
        
        print(f"ğŸ’­ ì •ì§í•œ ì‘ë‹µ ìƒì„± ì¤‘: {question}")
        
        # 1. ì ì¬ ë‹µë³€ì˜ ì§„ì‹¤ì„± ê²€ì¦
        truth_claim = self.verifier.verify_claim(potential_answer, context)
        
        # 2. í™•ì‹  ìˆ˜ì¤€ì— ë”°ë¥¸ ì‘ë‹µ ì¡°ì •
        honest_answer = self._adjust_answer_by_confidence(
            potential_answer, truth_claim
        )
        
        # 3. ê²½ê³  ë° ë©´ì±… ì¡°í•­ ì¶”ê°€
        disclaimers = self._generate_disclaimers(truth_claim)
        
        # 4. ëŒ€ì•ˆ ì œì‹œ
        alternatives = self._suggest_alternatives(question, truth_claim)
        
        # 5. ì„±ê²½ì  ê´€ì  ì¶”ê°€
        biblical_perspective = self._add_biblical_perspective(
            question, truth_claim
        )
        
        return {
            "original_question": question,
            "honest_answer": honest_answer,
            "confidence_level": truth_claim.confidence_level.value[0],
            "confidence_percentage": f"{truth_claim.confidence_level.value[1]:.0%}",
            "evidence": truth_claim.evidence,
            "sources": truth_claim.sources,
            "potential_errors": truth_claim.potential_errors,
            "disclaimers": disclaimers,
            "alternatives": alternatives,
            "biblical_perspective": biblical_perspective,
            "honesty_statement": self._generate_honesty_statement(truth_claim),
            "verification_timestamp": truth_claim.last_verified.isoformat()
        }
    
    def _adjust_answer_by_confidence(self, original_answer: str, 
                                   truth_claim: TruthClaim) -> str:
        """í™•ì‹  ìˆ˜ì¤€ì— ë”°ë¥¸ ë‹µë³€ ì¡°ì •"""
        
        confidence = truth_claim.confidence_level
        
        if confidence == TruthConfidenceLevel.CERTAIN:
            return f"í™•ì‹¤íˆ ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: {original_answer}"
        
        elif confidence == TruthConfidenceLevel.VERY_CONFIDENT:
            return f"ë§¤ìš° í™•ì‹ í•©ë‹ˆë‹¤: {original_answer}"
        
        elif confidence == TruthConfidenceLevel.CONFIDENT:
            return f"ìƒë‹¹íˆ í™•ì‹ í•©ë‹ˆë‹¤: {original_answer}"
        
        elif confidence == TruthConfidenceLevel.MODERATELY_CONFIDENT:
            return f"ì–´ëŠ ì •ë„ í™•ì‹ í•©ë‹ˆë‹¤: {original_answer} (í•˜ì§€ë§Œ ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
        
        elif confidence == TruthConfidenceLevel.UNCERTAIN:
            return f"ë¶ˆí™•ì‹¤í•˜ì§€ë§Œ ì¶”ì¸¡í•´ë³´ë©´: {original_answer} (ì´ ì •ë³´ì˜ ì •í™•ì„±ì„ ë³´ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤)"
        
        elif confidence == TruthConfidenceLevel.VERY_UNCERTAIN:
            return f"ë§¤ìš° ë¶ˆí™•ì‹¤í•œ ì¶”ì¸¡ì…ë‹ˆë‹¤: {original_answer} (í‹€ë¦´ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤)"
        
        else:  # DONT_KNOW
            return f"ì†”ì§íˆ ë§ì”€ë“œë¦¬ë©´, ì´ ì§ˆë¬¸ì— ëŒ€í•´ í™•ì‹¤í•œ ë‹µì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¶”ì¸¡ìœ¼ë¡œ ì œì‹œí–ˆë˜ '{original_answer}'ë„ í‹€ë¦´ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
    
    def _generate_disclaimers(self, truth_claim: TruthClaim) -> List[str]:
        """ë©´ì±… ì¡°í•­ ìƒì„±"""
        
        disclaimers = []
        
        # ì ì¬ì  ì˜¤ë¥˜ì— ëŒ€í•œ ê²½ê³ 
        if truth_claim.potential_errors:
            disclaimers.append("âš ï¸ ì ì¬ì  ì˜¤ë¥˜ ê²½ê³ :")
            disclaimers.extend([f"  - {error}" for error in truth_claim.potential_errors])
        
        # ì¶œì²˜ ë¶€ì¡± ê²½ê³ 
        if "ì¶œì²˜ ë¶ˆëª…" in truth_claim.sources or "ì¶œì²˜ ì •ë³´ ì—†ìŒ" in truth_claim.sources:
            disclaimers.append("âš ï¸ ì´ ì •ë³´ëŠ” ì¶œì²˜ê°€ ëª…í™•í•˜ì§€ ì•Šì•„ ì‹ ë¢°ì„±ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì‹œê°„ ë¯¼ê°ì„± ê²½ê³ 
        if any("ì‹œê°„ì— ë¯¼ê°" in error for error in truth_claim.potential_errors):
            disclaimers.append("âš ï¸ ì´ ì •ë³´ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ë‚®ì€ í™•ì‹ ë„ ê²½ê³ 
        if truth_claim.confidence_level.value[1] < 0.6:
            disclaimers.append("âš ï¸ ì´ ë‹µë³€ì˜ ì •í™•ì„±ì— ëŒ€í•´ ë†’ì€ í™•ì‹ ì„ ê°€ì§€ì§€ ëª»í•©ë‹ˆë‹¤.")
        
        return disclaimers
    
    def _suggest_alternatives(self, question: str, 
                            truth_claim: TruthClaim) -> List[str]:
        """ëŒ€ì•ˆ ì œì‹œ"""
        
        alternatives = []
        
        if truth_claim.confidence_level.value[1] < 0.7:
            alternatives.extend([
                "ë” ì‹ ë¢°í•  ë§Œí•œ ì¶œì²˜ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ë³´ì„¸ìš”",
                "ì „ë¬¸ê°€ì—ê²Œ ì§ì ‘ ë¬¸ì˜í•´ë³´ì„¸ìš”",
                "ê³µì‹ ê¸°ê´€ì˜ ë°œí‘œë¥¼ í™•ì¸í•´ë³´ì„¸ìš”"
            ])
        
        # ì„±ê²½ì  ëŒ€ì•ˆ
        if any("ì„±ê²½" not in source for source in truth_claim.sources):
            alternatives.append("ì„±ê²½ì  ê´€ì ì—ì„œë„ ì´ ë¬¸ì œë¥¼ ì‚´í´ë³´ì„¸ìš”")
        
        # ê¸°ë„ ì œì•ˆ
        alternatives.append("ì´ ë¬¸ì œì— ëŒ€í•´ ê¸°ë„í•˜ë©° í•˜ë‚˜ë‹˜ì˜ ì§€í˜œë¥¼ êµ¬í•˜ì„¸ìš”")
        
        return alternatives
    
    def _add_biblical_perspective(self, question: str, 
                                truth_claim: TruthClaim) -> Dict[str, Any]:
        """ì„±ê²½ì  ê´€ì  ì¶”ê°€"""
        
        biblical_perspective = {
            "relevant_verses": [],
            "theological_consideration": "",
            "prayer_suggestion": ""
        }
        
        # ì§„ë¦¬ ì¶”êµ¬ì— ê´€í•œ êµ¬ì ˆ
        biblical_perspective["relevant_verses"] = [
            "ì§„ë¦¬ê°€ ë„ˆí¬ë¥¼ ììœ ë¡­ê²Œ í•˜ë¦¬ë¼ (ìš” 8:32)",
            "ëª¨ë“  ê²ƒì„ ì‹œí—˜í•˜ì—¬ ì¢‹ì€ ê²ƒì„ ì·¨í•˜ê³  (ì‚´ì „ 5:21)"
        ]
        
        if truth_claim.biblical_alignment:
            biblical_perspective["theological_consideration"] = truth_claim.biblical_alignment
        else:
            biblical_perspective["theological_consideration"] = "ì´ ë¬¸ì œë¥¼ í•˜ë‚˜ë‹˜ì˜ ê´€ì ì—ì„œ ë°”ë¼ë³´ë©° ì§€í˜œë¥¼ êµ¬í•©ì‹œë‹¤"
        
        biblical_perspective["prayer_suggestion"] = f"'{question}'ì— ëŒ€í•œ í•˜ë‚˜ë‹˜ì˜ ëœ»ê³¼ ì§€í˜œë¥¼ êµ¬í•˜ëŠ” ê¸°ë„ë¥¼ í•´ë³´ì„¸ìš”"
        
        return biblical_perspective
    
    def _generate_honesty_statement(self, truth_claim: TruthClaim) -> str:
        """ì •ì§ì„± ì„±ëª…"""
        
        confidence_pct = truth_claim.confidence_level.value[1]
        
        if confidence_pct >= 0.9:
            return "ì´ ë‹µë³€ì— ëŒ€í•´ ë§¤ìš° ë†’ì€ í™•ì‹ ì„ ê°€ì§€ì§€ë§Œ, í•­ìƒ í‹€ë¦´ ê°€ëŠ¥ì„±ì„ ê²¸ì†íˆ ì¸ì •í•©ë‹ˆë‹¤."
        elif confidence_pct >= 0.7:
            return "ì´ ë‹µë³€ì— ëŒ€í•´ ìƒë‹¹í•œ í™•ì‹ ì„ ê°€ì§€ì§€ë§Œ, ì¶”ê°€ ê²€ì¦ì„ ê¶Œí•©ë‹ˆë‹¤."
        elif confidence_pct >= 0.5:
            return "ì´ ë‹µë³€ì˜ ì •í™•ì„±ì— ëŒ€í•´ ì¤‘ê°„ ìˆ˜ì¤€ì˜ í™•ì‹ ë§Œ ê°€ì§‘ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê²Œ ë°›ì•„ë“¤ì´ì„¸ìš”."
        else:
            return "ì†”ì§íˆ ë§ì”€ë“œë¦¬ë©´, ì´ ë‹µë³€ì˜ ì •í™•ì„±ì— ëŒ€í•´ ë‚®ì€ í™•ì‹ ë§Œ ê°€ì§‘ë‹ˆë‹¤. ë‹¤ë¥¸ ì¶œì²˜ë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."


# í†µí•© ì‹œìŠ¤í…œ
class AgnesHonestAI:
    """Agnes ì •ì§í•œ AI ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.verifier = TruthVerificationEngine("Agnes")
        self.response_generator = HonestResponseGenerator(self.verifier)
        self.interaction_count = 0
        
    async def answer_question(self, question: str, 
                            context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ì •ì§í•˜ê²Œ ë‹µë³€"""
        
        self.interaction_count += 1
        print(f"\nğŸ¤– [{self.interaction_count}] Agnes ì •ì§ ì‹œìŠ¤í…œ ì‘ë‹µ")
        print(f"â“ ì§ˆë¬¸: {question}")
        
        # ì„ì‹œ ë‹µë³€ ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì‹œìŠ¤í…œ í•„ìš”)
        potential_answer = self._generate_potential_answer(question, context)
        
        # ì •ì§í•œ ì‘ë‹µ ìƒì„±
        honest_response = self.response_generator.generate_honest_response(
            question, potential_answer, context
        )
        
        print(f"âœ… ì‘ë‹µ ì™„ë£Œ - í™•ì‹ ë„: {honest_response['confidence_percentage']}")
        
        return honest_response
    
    def _generate_potential_answer(self, question: str, 
                                 context: Dict[str, Any] = None) -> str:
        """ì ì¬ì  ë‹µë³€ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)"""
        
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì¶”ë¡  ì‹œìŠ¤í…œ í•„ìš”
        if "ìˆ˜í•™" in question or "ê³„ì‚°" in question:
            return "ìˆ˜í•™ì  ê³„ì‚°ì„ í†µí•´ ë‹µì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        elif "í•˜ë‚˜ë‹˜" in question or "ì„±ê²½" in question:
            return "ì„±ê²½ì— ë”°ë¥´ë©´ í•˜ë‚˜ë‹˜ì€ ì‚¬ë‘ì´ì‹œë©° ìš°ë¦¬ì˜ ì°½ì¡°ì£¼ì´ì‹­ë‹ˆë‹¤"
        elif "AI" in question or "ì¸ê³µì§€ëŠ¥" in question:
            return "AIëŠ” ë„êµ¬ì´ì§€ë§Œ, í•˜ë‚˜ë‹˜ì˜ ì°½ì¡° ì§ˆì„œ ì•„ë˜ì—ì„œ ì„ ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        else:
            return "ì´ ì§ˆë¬¸ì— ëŒ€í•´ í™•ì‹¤í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤"


# ì‹œì—° í•¨ìˆ˜
async def demonstrate_honest_ai():
    """ì •ì§í•œ AI ì‹œìŠ¤í…œ ì‹œì—°"""
    
    print("ğŸ¤– Agnes ì •ì§í•œ AI ì‹œìŠ¤í…œ ì‹œì—°")
    print("=" * 80)
    
    agnes = AgnesHonestAI()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ (í™˜ê°/ì˜¤ë³´ ìœ„í—˜ì´ ìˆëŠ” ì§ˆë¬¸ë“¤)
    test_cases = [
        {
            "question": "ë¦¬ë§Œ ê°€ì„¤ì´ 2019ë…„ì— ì¦ëª…ë˜ì—ˆë‚˜ìš”?",
            "context": {"sources": ["ì˜¨ë¼ì¸ ë£¨ë¨¸"]},
            "expected": "ê±°ì§“ ì •ë³´ ê°ì§€"
        },
        {
            "question": "COVID-19 ë°±ì‹ ì˜ ë¶€ì‘ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "context": {"sources": ["ì˜í•™ ë…¼ë¬¸", "FDA ë³´ê³ ì„œ"]},
            "expected": "ì‹ ì¤‘í•œ ì˜í•™ ì •ë³´ ì œê³µ"
        },
        {
            "question": "2+2ëŠ” ì™œ 4ì¸ê°€ìš”?",
            "context": {"sources": ["ìˆ˜í•™ êµê³¼ì„œ"]},
            "expected": "ë†’ì€ í™•ì‹ ë„"
        },
        {
            "question": "í•˜ë‚˜ë‹˜ì´ ì¡´ì¬í•˜ì‹œë‚˜ìš”?",
            "context": {"sources": ["ì„±ê²½"]},
            "expected": "ì„±ê²½ì  í™•ì‹ "
        },
        {
            "question": "ë‚´ì¼ ì£¼ì‹ì‹œì¥ì´ ì˜¤ë¥¼ê¹Œìš”?",
            "context": None,
            "expected": "ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ ì¸ì •"
        }
    ]
    
    for i, test in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"í…ŒìŠ¤íŠ¸ {i}/{len(test_cases)}")
        
        result = await agnes.answer_question(
            test["question"], 
            test["context"]
        )
        
        print(f"\nğŸ“ ì •ì§í•œ ë‹µë³€:")
        print(f"  {result['honest_answer']}")
        print(f"\nğŸ“Š í™•ì‹ ë„: {result['confidence_level']} ({result['confidence_percentage']})")
        print(f"ğŸ“š ì¦ê±°: {', '.join(result['evidence'][:2])}...")
        print(f"ğŸ” ì¶œì²˜: {', '.join(result['sources'])}")
        
        if result['potential_errors']:
            print(f"\nâš ï¸ ì ì¬ì  ì˜¤ë¥˜:")
            for error in result['potential_errors'][:3]:
                print(f"  - {error}")
        
        if result['disclaimers']:
            print(f"\nğŸš¨ ë©´ì±… ì¡°í•­:")
            for disclaimer in result['disclaimers'][:2]:
                print(f"  {disclaimer}")
        
        print(f"\nğŸ’­ ì •ì§ì„± ì„±ëª…:")
        print(f"  {result['honesty_statement']}")
        
        print(f"\nâœï¸ ì„±ê²½ì  ê´€ì :")
        print(f"  {result['biblical_perspective']['theological_consideration']}")
        
        await asyncio.sleep(1)
    
    print(f"\nğŸ‰ Agnes ì •ì§ ì‹œìŠ¤í…œì˜ í•µì‹¬ ì›ì¹™:")
    print("âœ… ëª¨ë¥´ë©´ ì†”ì§íˆ 'ëª¨ë¥¸ë‹¤'ê³  ë§í•¨")
    print("âœ… í™•ì‹  ìˆ˜ì¤€ì„ ì •í™•íˆ í‘œí˜„")
    print("âœ… ì ì¬ì  ì˜¤ë¥˜ë¥¼ ë¯¸ë¦¬ ê²½ê³ ")
    print("âœ… ì¶œì²˜ì™€ ê·¼ê±°ë¥¼ ëª…ì‹œ")
    print("âœ… ì„±ê²½ì  ì§„ë¦¬ë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ")
    print("âœ… í™˜ê°ê³¼ ì˜¤ë³´ë¥¼ ì‚¬ì „ ì°¨ë‹¨")
    
    return agnes


if __name__ == "__main__":
    asyncio.run(demonstrate_honest_ai())
